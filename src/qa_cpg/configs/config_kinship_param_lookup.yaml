model:
  entity_embedding_size: 200
  relation_embedding_size: 1
  concat_rel: False          # Set to `False` for plain ConvE, 'True' only if you want the relation to be concatenated in in the projection/output layer.
  input_dropout: 0.5
  feature_map_dropout: 0.5
  output_dropout: 0.5
  label_smoothing_epsilon: 0.1
  batch_norm_momentum: 0.1
  batch_norm_train_stats: False # If true, during training, batch norm will use a moving average of train samples.
  do_parameter_lookup: True
context:
  context_rel_conv:          # Leave empty for plain ConvE. Put list of hidden layer sizes for CPG.
  context_rel_out: []          # Leave empty for plain ConvE. Put list of hidden layer sizes for CPG.
  context_rel_dropout: 0.5
  context_rel_use_batch_norm: True
training:
  learning_rate: 0.001
  batch_size: 512
  device: '/GPU:0'
  max_steps: 8000
  prop_negatives: 10.0
  num_labels: 100            # Total number of labels considered during training when doing negative sampling. Must be > prop_negatives.
  one_positive_label_per_sample: False  # If True, it uses one positive answer per sample, and fills up tp num_labels with negatives.
  cache_data: True
eval:
  validation_metric: hits@1  # Choose among: mr, mrr, hits@1, hits@10, hits@20.
  log_steps: 50
  ckpt_steps: 1000
  eval_steps: 10
  summary_steps: 10
  eval_on_train: False
  eval_on_dev: True
  eval_on_test: True
  add_loss_summaries: True
  add_variable_summaries: False
  add_tensor_summaries: False
